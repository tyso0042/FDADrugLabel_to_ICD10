{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ab868e3-b212-430d-b1a9-8323773db2b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Patrick Tyson**\n",
    "\n",
    "- **Description**: Write a program that maps drugs to related diagnoses\n",
    "\n",
    "- **Drug Class Analyzed** - Recombinant Human Growth Hormone - abuse of HGH\n",
    "\n",
    "- **Diagnosis Information used**:\n",
    "    - Int'l Classification of Diseases (#10)\n",
    "    - Drug Data - National Drug Code (NDC)\n",
    "\n",
    "- Program takes two input files, one for drugs, other for diagnoses\n",
    "    - Takes the drug file, pulls back label info from openFDA API\n",
    "\n",
    "- Label and Diagnoses are then put into N-grams sets\n",
    "\n",
    "     - Intersection of sets is shared wording between drug and diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414bbcca-5f52-4b67-b89d-c1292ae99532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import regex\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba81855-73ea-429f-b981-7b7aa0ce469c",
   "metadata": {},
   "source": [
    "## Getting Stop Words for text mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5c501e-c2df-4fa6-bde2-a2c2842ccea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words.add('due')\n",
    "stop_words.add('age')\n",
    "stop_words.add('associated')\n",
    "stop_words.add('onset')\n",
    "stop_words.add('secondary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238bcd6-eb40-4930-bd72-97eb8145197a",
   "metadata": {},
   "source": [
    "## Getting tokenize ability for strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0a3b8e-af00-46c1-9a8f-c97dcfed0947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba57b8-7ead-4c2c-9325-85d5eb35f9e8",
   "metadata": {},
   "source": [
    "### Creating Text Mining Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2254ec-624b-4ce8-ac2f-7b4abe1eff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Mining_String:\n",
    "    # Construct a text mining string object\n",
    "    def __init__(self, text_data=''):\n",
    "        self.__text_data = text_data\n",
    "\n",
    "    # creating functions to perform various text mining prep steps\n",
    "    def get_text_data(self):\n",
    "        return self.__text_data\n",
    "\n",
    "    # creating functions set values for various text mining prep steps\n",
    "    def set_text_data(self, text_data):\n",
    "        self.__text_data = text_data\n",
    "\n",
    "    # functions for text mining\n",
    "    # returns text source in lower case and without punctuation\n",
    "    def lower_case(self):\n",
    "        low = str(self.__text_data)\n",
    "        low = low.lower()\n",
    "        return low\n",
    "\n",
    "    # returns text with punctuation removed\n",
    "    def remove_punctuation(self, string_data):\n",
    "        if not string_data:\n",
    "            return 'NA'\n",
    "        else:\n",
    "            r_p = str(string_data)\n",
    "            r_p = regex.sub(\"('s)\", '', r_p)\n",
    "            no_punct = regex.sub(r'[^0-z\\s]', ' ', r_p)\n",
    "            no_punct = ' '.join(no_punct.split())\n",
    "            return no_punct\n",
    "\n",
    "    # creates string for each word\n",
    "    def tokenize(self, string_data):\n",
    "        if not string_data:\n",
    "            return 'NA'\n",
    "        else:\n",
    "            tokens = [tk for tk in string_data.split(' ') if tk != \"\"]\n",
    "            return tokens\n",
    "\n",
    "    # removes common english words that mostly create noise for model\n",
    "    def remove_stopwords(self, string_data):\n",
    "        if not string_data:\n",
    "            return 'NA'\n",
    "        else:\n",
    "            # list comprehension to create list of non-stop words\n",
    "            tokens_no_stop = ([w for w in string_data if w not in stop_words])\n",
    "            return tokens_no_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65de7a-d8b6-4d81-b5b3-86f229e6540a",
   "metadata": {},
   "source": [
    "### Subclass of Text Mining String, adding ability to create n-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5979b75-f69b-4e9e-97c0-dfa736e953f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class N_Grams(Text_Mining_String):\n",
    "    def __init__(self, ngrams, text_data):\n",
    "        # inheriting all Text Mining String arguments, adding ngram argument\n",
    "        super().__init__(text_data)\n",
    "        self.__ngrams = ngrams\n",
    "        self.__text_data = text_data\n",
    "\n",
    "    def get_ngrams(self):\n",
    "        return self.__ngrams\n",
    "\n",
    "    def set_ngrams(self, ngrams):\n",
    "        self.__ngrams = ngrams\n",
    "\n",
    "    # generating strings of n-values to match other strings\n",
    "    def generate_ngrams(self, string_data):\n",
    "        if not string_data:\n",
    "            return 'NA'\n",
    "        else:\n",
    "            # getting n of grams from class object\n",
    "            num = self.get_ngrams()\n",
    "            # zipping n-number of words together to form n-gram\n",
    "            if len(string_data) == 1:\n",
    "                return string_data\n",
    "            else:\n",
    "                n_g = zip(*[string_data[i:] for i in range(num)])\n",
    "                # joining as lists\n",
    "                ngrams_out = [\" \".join(ngram) for ngram in n_g]\n",
    "                return ngrams_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bacf13-b317-489a-bb9f-7fea01147f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55bc5dcb-df6e-48b6-9134-a7a691896afe",
   "metadata": {},
   "source": [
    "## Possible future enhancement, add a boolean value for reverse tokenization to account for different in sentence structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bb6f7-27c1-4cc1-9ae3-471a1af97355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d30cddd4-5339-4bf7-bef2-ef779e17d611",
   "metadata": {},
   "source": [
    "## Functions related to the API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d334ce-4db4-43f9-b1b1-e8df669ae312",
   "metadata": {},
   "source": [
    "### function to build out url for api requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a458760c-bbb1-4452-8bc3-97bb22baf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_output(url_beginning, query_data):\n",
    "    url_output = (url_beginning + query_data)\n",
    "    return url_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62dde7-8d65-4e71-a189-932d737b96a2",
   "metadata": {},
   "source": [
    "### Function for api call for set id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb95bf2-9ecd-4ac1-971f-74a4a6b19edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fda_set_id_call(url_output):\n",
    "    json_data = requests.get(url_output).json()\n",
    "\n",
    "    # if statement to take care of any not found errors\n",
    "    if json_data.get('error') is not None:\n",
    "        return \"Source Data Not Found\"\n",
    "\n",
    "    else:\n",
    "        # try to find the relevant data using parsing structure\n",
    "        # json data is series of lists and dictionaries\n",
    "        # have to use get() and list indices to parse through data\n",
    "        try:\n",
    "            target = (json_data.get('results')[0]\n",
    "                      .get('openfda')\n",
    "                      .get('spl_set_id')[0])\n",
    "\n",
    "            return target\n",
    "\n",
    "        # if the parsing structure for relevant data missing\n",
    "        except (AttributeError, TypeError):\n",
    "            # printing unique message for missing data\n",
    "            return \"Source Data Found, but Relevant Data Missing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a44a6-c071-44f1-a28f-dec1fef7b8be",
   "metadata": {},
   "source": [
    "### Function for api call for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6397eb1-dc68-4916-a7bd-aeb9f78f2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fda_label_call(url_output):\n",
    "    json_lbl = requests.get(url_output).json()\n",
    "\n",
    "    # if statement to take care of any not found errors\n",
    "    if json_lbl.get('error') is not None:\n",
    "        return \"Source Data Not Found\"\n",
    "\n",
    "    else:\n",
    "        # try to find the relevant data using parsing structure\n",
    "        # json data is series of lists and dictionaries\n",
    "        # have to use get() and list indices to parse through data\n",
    "        try:\n",
    "            label = (json_lbl\n",
    "                     .get('results')[0]\n",
    "                     .get('indications_and_usage'))\n",
    "            return label\n",
    "\n",
    "        # if the parsing structure for relevant data missing\n",
    "        except (AttributeError, TypeError):\n",
    "            # printing unique message for missing data\n",
    "            return \"Source Data Found, but Relevant Data Missing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2fcab-0948-47f7-afd5-b92cca3f6577",
   "metadata": {},
   "source": [
    "### Function to maintain traceability throughout process, storing in Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deb26648-33d9-488e-aa6b-52377f2c1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to add list to pandas dataframe\n",
    "def list_to_df(dataframe='', new_list='', column_name=''):\n",
    "    dataframe[column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231743ff-4af1-4831-8d17-113f0818667e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ba8cd3-cbed-47cb-967d-2eee7895fe73",
   "metadata": {},
   "source": [
    "# Input Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208533e-6b9d-4059-aadf-cafc76bb43cb",
   "metadata": {},
   "source": [
    "## DRUG INPUT FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2a898-e97f-49cf-b57f-a852a42d6be0",
   "metadata": {},
   "source": [
    "### Reading in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af0edd7b-26b2-4211-a9ae-84ca9839f55b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NDC_drug_source_file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31780/2959618534.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdrug_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"NDC_drug_source_file.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrug_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NDC_drug_source_file.csv'"
     ]
    }
   ],
   "source": [
    "drug_in = open(r\"NDC_drug_source_file.csv\", \"r\")\n",
    "reader = csv.DictReader(drug_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8723e-6697-470a-a5fe-440931467f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list to add NDC values to\n",
    "ndc_11_list = []\n",
    "drug_name_list = []\n",
    "# for loop to add values to NDC list\n",
    "for rdr in reader:\n",
    "    ndc_11_list.append(rdr['NDC'])\n",
    "    drug_name_list.append(rdr['PRD_LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bcdb4e-7df8-40bb-b777-d6a786b41fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2786ac8b-eccd-4df6-b219-d8f4e5a2f0d0",
   "metadata": {},
   "source": [
    "## DIAGNOSIS INPUT FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279aac04-4337-4766-9a0d-e2b8522d3b80",
   "metadata": {},
   "source": [
    "### Reading in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48533035-9c99-43f8-bfec-23822081150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_in = open(r\"ICD10_diagnosis_source_file.csv\", \"r\")\n",
    "reader2 = csv.DictReader(diagnosis_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bda55a-ae3f-4255-89a1-6e8e0773436c",
   "metadata": {},
   "source": [
    "## Creating lists to add ICD-10 values to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6effb88e-8b8e-4d6c-8b25-38b89929255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_10_block = []\n",
    "icd_10_desc = []\n",
    "# for loop to add values to ICD-10 code  list\n",
    "for rdr2 in reader2:\n",
    "    icd_10_block.append([rdr2['DIAGNOSIS_CODE']])\n",
    "    icd_10_desc.append([rdr2['DIAGNOSIS_DESC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90df6e8-433b-4560-ad1c-2c310095454a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebfab99e-fee1-4c00-b471-2e4adf6a549d",
   "metadata": {},
   "source": [
    "# FDA Label & NDC Data File Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa268dff-0367-4d7a-9dc0-0a02931be67a",
   "metadata": {},
   "source": [
    "Current NDC value has no leading zeros, and is in NDC-11 format.\n",
    "NDC-11 is used for billing a drug, but NDC-10 is displayed on the packaging\n",
    "Need to convert NDC-11 to NDC-10 in order to use API.\n",
    "\n",
    "https://phpa.health.maryland.gov/OIDEOR/IMMUN/Shared%20Documents/Handout%203%20-%20NDC%20conversion%20to%2011%20digits.pdf\n",
    "\n",
    "Three different formats, depending on where additional zero in NDC-11 format is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9668630-8aba-44df-a3b5-6c33f02962b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef76898-21a6-4fae-b08c-25b3fbe59f9c",
   "metadata": {},
   "source": [
    "## For loop to identify which type of conversion needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6d8fe-b478-4948-99bd-4861efde7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndc_10_list = []\n",
    "\n",
    "for j in ndc_11_list:\n",
    "    # if < 11 digits, leading zeros cut off, we pad left up to 10 digits\n",
    "    if len(j) < 11 or j[0] == '0':\n",
    "        ndc_10_list.append(j.zfill(10))\n",
    "\n",
    "    # if the 6th digit is a zero, then the 6th indexed zero gets cut\n",
    "    elif j[5] == '0':\n",
    "        # slicing up to 5th index, then starting at the 6th index\n",
    "        ndc_10_list.append(j[: 5] + j[6:])\n",
    "\n",
    "    # if the 2nd last digit is a zero, then the 2nd last indexed zero gets cut\n",
    "    elif j[-2] == '0':\n",
    "        # slicing up to second last digit, then just keeping last digit\n",
    "        ndc_10_list.append(j[:-2] + j[-1])\n",
    "\n",
    "    # not passing invalid NDCs to list for API call\n",
    "    else:\n",
    "        ndc_10_list.append('')\n",
    "        print(\"NDC {} is not valid.\".format(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e3a084-df5f-4d0c-8e55-e2618ddef57d",
   "metadata": {},
   "source": [
    "From here, we need to be able to trace the changes we make back to NDC-11.\n",
    "Creating pandas df, appending columns as we move through process.\n",
    "Pandas DF will how we establish traceability throughout process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7959a-5167-4492-aef3-64e2274a4252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c64006-9274-4aa5-b2ab-495a1b4a6998",
   "metadata": {},
   "source": [
    "## Creating drug data df to add new columns to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada09cde-2490-4a61-8c12-b0ab6db806f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_data = pd.DataFrame(ndc_11_list, columns=['NDC-11'])\n",
    "\n",
    "# calling list to df function\n",
    "list_to_df(drug_data, drug_name_list, 'Product Name')\n",
    "list_to_df(drug_data, ndc_10_list, 'NDC-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbdcc6-bd3b-450b-b465-c9854ded2c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca3d467d-4f3b-436e-a4da-05f4c70be5c0",
   "metadata": {},
   "source": [
    "## Need to reformat NDC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4beed-d0e1-435c-895d-81ae965ce694",
   "metadata": {},
   "source": [
    "### Need to format NDC as 4-4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409550f-d892-4a4d-a3f7-3a28df0679d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now ndc-10 list is done, need to format it with dashes 9999-9999-99\n",
    "pkg_ndc_442_list = []\n",
    "# for loop to add dashes in index 3 and 7\n",
    "for k in ndc_10_list:\n",
    "    pkg_ndc_442_list.append(k[:4] + '-' + k[4:8] + '-' + k[8:])\n",
    "\n",
    "# calling 442 list to df function\n",
    "list_to_df(drug_data, pkg_ndc_442_list, 'Package NDC (4-4-2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cac2e9-fbc9-433e-8c80-e6ea82141f27",
   "metadata": {},
   "source": [
    "### Need to format NDC as 5-3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4e83f-58bd-474b-8f61-f92d2839c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to format it 5-3-2\n",
    "pkg_ndc_532_list = []\n",
    "# for loop to add dashes in index 3 and 7\n",
    "for m in ndc_10_list:\n",
    "    pkg_ndc_532_list.append(m[:5] + '-' + m[5:8] + '-' + m[8:])\n",
    "\n",
    "# calling 532 list to df function\n",
    "list_to_df(drug_data, pkg_ndc_532_list, 'Package NDC (5-3-2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14026559-e3e5-47a6-8326-d0753feb9bff",
   "metadata": {},
   "source": [
    "### Need to format NDC as 5-4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769b31e-217d-4ed6-a418-e845d622b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to format it 5-4-1\n",
    "pkg_ndc_541_list = []\n",
    "# for loop to add dashes in index 3 and 7\n",
    "for n in ndc_10_list:\n",
    "    pkg_ndc_541_list.append(n[:5] + '-' + n[5:9] + '-' + n[9:])\n",
    "\n",
    "# calling 541 list to df function\n",
    "list_to_df(drug_data, pkg_ndc_541_list, 'Package NDC (5-4-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaac05d-dba7-4dcf-9549-476081754439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc2c9cd-5f4b-46fa-8217-5646aa15865e",
   "metadata": {},
   "source": [
    "Now we have the NDC used on the drug package label in each format.\n",
    "With the package NDC, we can query the OpenFDA API for the drug \"Set ID\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efccd5-0fad-48e8-ba51-88b26034befc",
   "metadata": {},
   "source": [
    "## Pulling Back FDA Label Information from openFDA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f564e697-5c8e-4c52-a772-f68d424c8433",
   "metadata": {},
   "source": [
    "### Creating for loop to get list of all set ids from 4-4-2 NDCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab453c1d-7300-479d-8ba9-14ccf18032cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating for loop to get list of all set ids from 4-4-2 NDCs\n",
    "ndc_442_set_id_list = []\n",
    "for p in range(0, len(pkg_ndc_442_list)):\n",
    "    # calling function to create url from inputs\n",
    "    url_out = url_output(\"https://api.fda.gov/drug/ndc.json?api_key=jX24nplX7IraJUJ6Fj2wacey0QNGxis8aljnENKA&search=packaging.package_ndc:\", pkg_ndc_442_list[p])\n",
    "    # calling set id parse function\n",
    "    set_id = fda_set_id_call(url_out.strip())\n",
    "    # appending to list\n",
    "    ndc_442_set_id_list.append(set_id)\n",
    "    # forcing system to wait, only allowed 240 requests/minute\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# adding 442 set id list to df\n",
    "list_to_df(drug_data, ndc_442_set_id_list, 'Set ID (4-4-2)')\n",
    "print('All 4-4-2 requests completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57814c-43f2-469f-ae49-7128feceaf83",
   "metadata": {},
   "source": [
    "### creating for loop to get list of all set ids from 5-3-2 NDCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fb82b-c1cf-4526-b5b3-222cd3dd726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndc_532_set_id_list = []\n",
    "for q in range(0, len(pkg_ndc_532_list)):\n",
    "    # calling function to create url from inputs\n",
    "    url_out = url_output(\"https://api.fda.gov/drug/ndc.json?api_key=jX24nplX7IraJUJ6Fj2wacey0QNGxis8aljnENKA&search=packaging.package_ndc:\", pkg_ndc_532_list[q])\n",
    "    # calling set id parse function\n",
    "    set_id = fda_set_id_call(url_out.strip())\n",
    "    # appending to list\n",
    "    ndc_532_set_id_list.append(set_id)\n",
    "    # forcing system to wait, only allowed 240 requests/minute\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# adding 532 set id list to df\n",
    "list_to_df(drug_data, ndc_532_set_id_list, 'Set ID (5-3-2)')\n",
    "print('All 5-3-2 requests completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a4f58-62bb-4c42-9312-bdb665424aaa",
   "metadata": {},
   "source": [
    "### Creating for loop to get list of all set ids from 5-4-1 NDCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ef270-55fa-43c0-9b4d-a845030539ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndc_541_set_id_list = []\n",
    "for r in range(0, len(pkg_ndc_541_list)):\n",
    "    # calling function to create url from inputs\n",
    "    url_out = url_output(\"https://api.fda.gov/drug/ndc.json?api_key=jX24nplX7IraJUJ6Fj2wacey0QNGxis8aljnENKA&search=packaging.package_ndc:\", pkg_ndc_541_list[r])\n",
    "    # calling set id parse function\n",
    "    set_id = fda_set_id_call(url_out.strip())\n",
    "    # appending to list\n",
    "    ndc_541_set_id_list.append(set_id)\n",
    "    # forcing system to wait, only allowed 240 requests/minute\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# adding 541 set id list to df\n",
    "list_to_df(drug_data, ndc_541_set_id_list, 'Set ID (5-4-1)')\n",
    "print('All 5-4-1 requests completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ee7d4-4070-4ec3-b951-7b67858c3766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac0dcd3-7592-4ac9-95b4-d610f221d467",
   "metadata": {},
   "source": [
    "We now have set ids based on all three formats.\n",
    "Want to create a single list of set ids to pull label information from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2a391-4831-4f3f-833d-b8a688836ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28fc8f-4061-4459-a54f-4650bbeeda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndc_set_id_list = []\n",
    "# looping through rows in pandas df to get set id if available\n",
    "for row in (drug_data[['Set ID (4-4-2)', 'Set ID (5-3-2)', 'Set ID (5-4-1)']]\n",
    "            .itertuples()):\n",
    "    if 'Source' in row[1]:\n",
    "        if 'Source' in row[2]:\n",
    "            if 'Source' in row[3]:\n",
    "                ndc_set_id_list.append('NA')\n",
    "            else:\n",
    "                ndc_set_id_list.append(row[3])\n",
    "        else:\n",
    "            ndc_set_id_list.append(row[2])\n",
    "    else:\n",
    "        ndc_set_id_list.append(row[1])\n",
    "\n",
    "\n",
    "# adding set id list to df\n",
    "list_to_df(drug_data, ndc_set_id_list, 'Set ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a088877-7cb5-4069-90cc-10e2bc55f9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4676fa27-2f1c-479f-af33-e32650036bb6",
   "metadata": {},
   "source": [
    "Now that we have the set ids, we can query the system again and pull label info\n",
    "We will pass the set ids into the API, and retrieve the label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8901d-5715-4f4a-b991-9c5a1c7a494e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47d85533-c04e-46eb-98c0-b20affeb6fa7",
   "metadata": {},
   "source": [
    "## Creating for loop to get label using set id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd740fd-982e-4562-ab00-a1b8426cb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating for loop to get label using set id\n",
    "label_list = []\n",
    "for s in range(0, len(ndc_set_id_list)):\n",
    "    # calling function to create url from inputs\n",
    "    url_out = url_output(\"https://api.fda.gov/drug/label.json?api_key=jX24nplX7IraJUJ6Fj2wacey0QNGxis8aljnENKA&search=set_id:\", ndc_set_id_list[s])\n",
    "#    print(url_out)\n",
    "    if ndc_set_id_list[s] == 'NA' or url_out == []:\n",
    "        label_list.append([])\n",
    "    else:\n",
    "        # calling set id parse function\n",
    "        label = fda_label_call(\"{}\".format(url_out))\n",
    "        # appending to list\n",
    "        label_list.append(label)\n",
    "    # forcing system to wait, only allowed 240 requests/minute\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e0e79-12b9-4392-a1b3-b2697ea02c30",
   "metadata": {},
   "source": [
    "### Adding label list to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661b12c-3625-4f00-9b5b-1909e47bf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_df(drug_data, label_list, 'Label - Indications and Usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2a9a4-8491-4325-af9b-6535e29c5499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0f2a33a-e90b-4289-9f63-1944eab0323e",
   "metadata": {},
   "source": [
    "Common FDA labeling practice is to say \"Drug X is indicated for...\"\n",
    "Then list the diagnoses the drugs treat\n",
    "\n",
    "We only want to include sentences with \"indicated for\" from the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1c510-87f8-4bf9-8c3f-a161d943a068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668469b-47c0-4ec7-bb8b-bd2cf2fc07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating blank list to append\n",
    "label_indications_list = []\n",
    "for t in label_list:\n",
    "    if not t:\n",
    "        label_indications_list.append('NA')\n",
    "\n",
    "    else:\n",
    "        # regex used to pick out sentences that contain \"indicated for\"\n",
    "        lbl_ind_all = regex.findall(r'([^.]*indicated for[^.]*)', t[0])\n",
    "        # need to join multiple sentences into 1 paragraph\n",
    "        lbl_ind_all_new = '.'.join(lbl_ind_all)\n",
    "        # regex to remove sentences with \"not indicated for\"\n",
    "        lbl_ind = regex.sub(r'([^.]*not indicated for[^.]*)',\n",
    "                            '', lbl_ind_all_new)\n",
    "        label_indications_list.append(lbl_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1cf46-f328-402b-878e-25ea92fc2538",
   "metadata": {},
   "source": [
    "## Adding label indications list to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d88825-16d1-49d0-8b23-2a26a0838801",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_df(drug_data, label_indications_list, 'Label - Indications Only')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a4851a9-b52b-4905-a234-c8b2713ad3e7",
   "metadata": {},
   "source": [
    "label_indications_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d16c8-5010-4756-9f21-ef504002c4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deee836c-442d-47e1-b30a-2492c116ad26",
   "metadata": {},
   "source": [
    "# Now we have our data ready for to begin ngramming and mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecddc5b-9c76-4495-9edc-18ee93cd473d",
   "metadata": {},
   "source": [
    "## Building FDA Drug Label N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7cbe0-5d7e-42ef-b871-25c420dbc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing a list to store cleansed label information\n",
    "ngram_drug_list_lists = [list(), list(), list(), list(), list()]\n",
    "temp_list = []\n",
    "\n",
    "for u in range(1, 6):\n",
    "    for v in label_indications_list:\n",
    "        # creating NGrams object with variable text data\n",
    "        txt_obj = N_Grams(text_data=v, ngrams=u)\n",
    "        # stepping through each function and applying\n",
    "        label_string = txt_obj.lower_case()\n",
    "        label_string = txt_obj.remove_punctuation(label_string)\n",
    "        label_string = txt_obj.tokenize(label_string)\n",
    "        label_string = txt_obj.remove_stopwords(label_string)\n",
    "        label_string = txt_obj.generate_ngrams(label_string)\n",
    "        # appending data to list after process complete\n",
    "        temp_list.append(label_string)\n",
    "    # appending temp list to list of lists\n",
    "    ngram_drug_list_lists[u-1].append(temp_list)\n",
    "    # resetting temp list for next run\n",
    "    temp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550e072-8b53-45c1-a17f-971dc0070369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b1334d3-97f8-4719-bdf4-40ff0fe4f6f3",
   "metadata": {},
   "source": [
    "Now our drug data is ready, so we need to prepare the diagnosis info\n",
    "\n",
    "Will be using the ICD-10 (International Classification of Diseases)\n",
    "\n",
    "In order to cut down on computation I am using the first 3 characters or block\n",
    "\n",
    "Full code is longer and contains 70000+ codes vs ~1900 I am using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d34fb0-e07e-4496-be68-d8723bbb5e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ff1c33-7458-445a-8bb4-683f14f2a718",
   "metadata": {},
   "source": [
    "## Building Diagnosis N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317aea7a-c21c-4b2f-b570-5f0990cd0563",
   "metadata": {},
   "source": [
    "### Creating new pandas df to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd05c1-a471-4f1c-a2a1-410126c31222",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_data = pd.DataFrame()\n",
    "# adding lists to new df\n",
    "list_to_df(diagnosis_data, icd_10_block, 'ICD-10 Code Block')\n",
    "list_to_df(diagnosis_data, icd_10_desc, 'ICD-10 Description')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07993907-6c9d-420a-b39b-b08f639a881e",
   "metadata": {},
   "source": [
    "### Creating N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90721208-1c67-4b93-9a0a-e7b30dcfa84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing a list of lists to store diagnosis ngram information\n",
    "ngram_diag_list_lists = [list(), list(), list(), list(), list()]\n",
    "\n",
    "temp_list = []\n",
    "for y in range(1, 6):\n",
    "    for z in icd_10_desc:\n",
    "        diag_obj = N_Grams(text_data=z, ngrams=y)\n",
    "        # stepping through each function and applying\n",
    "        diag_string = diag_obj.lower_case()\n",
    "        diag_string = diag_obj.remove_punctuation(diag_string)\n",
    "        diag_string = diag_obj.tokenize(diag_string)\n",
    "        diag_string = diag_obj.remove_stopwords(diag_string)\n",
    "        diag_string = diag_obj.generate_ngrams(diag_string)\n",
    "        # appending data to list after process complete\n",
    "        temp_list.append(diag_string)\n",
    "    # appending temp list to list of lists\n",
    "    ngram_diag_list_lists[y-1].append(temp_list)\n",
    "    temp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74fa3d3-b6e8-4134-ac07-b7eb874529c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9283b9f0-03ac-4e53-926b-cecb45dbb66f",
   "metadata": {},
   "source": [
    "# Set Intersection of Drug Label vs Diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee716e-fcd4-450a-a49c-d428cb65db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating reference lists to help with readability of for loops\n",
    "drug_ngrams = ngram_drug_list_lists[1][0]\n",
    "diag_ngrams = ngram_diag_list_lists[1][0]\n",
    "\n",
    "# creating empty list to append\n",
    "intersection_list = []\n",
    "# enumerating through drug bigrams\n",
    "for a, b in enumerate(drug_ngrams):\n",
    "    # putting bigrams into set to eliminate duplicates & allow for intersection\n",
    "    drug_ngrams_set = {*b}\n",
    "    # enumerating through diagnosis bigrams\n",
    "    for c, d in enumerate(diag_ngrams):\n",
    "        # creating diagnosis bigram set\n",
    "        diag_ngrams_set = {*d}\n",
    "        # finding matching bigram pairs using set intersection\n",
    "        intersection = drug_ngrams_set.intersection(diag_ngrams_set)\n",
    "        if intersection != set():\n",
    "            #print(\"Drug Index = {}, Diagnosis Index = {}, shared wording = {}\"\n",
    "                  #.format(a, c, intersection))\n",
    "            # appending intersection data to list\n",
    "            # also adding the indices for both the drug and diagnosis lists\n",
    "            intersection_list.append([a, c, intersection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0628a-5816-41ed-b7e5-430887c1406a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb5ae18-04d9-43c7-9fbb-0e090b7b865c",
   "metadata": {},
   "source": [
    "## Ceating pandas dataframe in order to merge into other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5733da7-eb69-4e50-addd-409678031438",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_df = pd.DataFrame(intersection_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50311280-e9e7-468b-9dbc-f3221fc29b1c",
   "metadata": {},
   "source": [
    "### Naming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b7f44-e65e-42d4-a3fa-103f436f0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_df.columns = ['drug index', 'diagnosis index', 'shared wording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47a91f-2d1d-41fc-9245-311a7afc2545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c23e25a1-6b70-48e0-8f4d-f2bf90f01d3c",
   "metadata": {},
   "source": [
    "### Merge intersection data with drug dataframe, select columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fb5fd-3c5c-4df4-9e51-abf4248073e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(intersection_df, drug_data.iloc[:, [0, 1, 10]],\n",
    "                     how='left', left_on='drug index', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bdd0a-72e5-403a-8154-bdd5f49c4779",
   "metadata": {},
   "source": [
    "### Merge intersection data with diagnosis dataframe, select columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120998bc-09bb-447f-9a84-fe20e6893408",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, diagnosis_data.iloc[:, [0, 1]],\n",
    "                     how='left', left_on='diagnosis index', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbaffc6-47b7-4b3a-a2ad-f72f8788efcf",
   "metadata": {},
   "source": [
    "This is the final output, you can see both the drug and diagnosis info\n",
    "Map shows a Drug, the related diagnoses, and the wording shared between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7c3cf-0842-4e37-98c0-e47cb843bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f7edc-6db3-4f90-a10b-d1f51dd7b54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
